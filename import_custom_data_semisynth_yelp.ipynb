{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and format custom datasets for SCHOLAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, scipy, json\n",
    "from scipy import sparse\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import file_handling as fh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0 | 0.5 | 0.0\n",
    "gamma = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data and save in SCHOLAR format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/home/maxa/data/semisynth_yelp/ \n",
      " /nfs/home/maxa/data/semisynth_yelp/scholar_gamma0.0/\n"
     ]
    }
   ],
   "source": [
    "if sys.platform == \"darwin\":\n",
    "    pass\n",
    "else:\n",
    "    raw_data_path = \"/nfs/home/maxa/data/semisynth_yelp/\"\n",
    "    output_dir = raw_data_path + \"scholar_gamma\"+str(gamma)+\"/\"\n",
    "print(raw_data_path, \"\\n\",output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see empirical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bow_raw = pd.read_csv(\"/nfs/home/maxa/data/yelp_btr/preprocessed/yelp_dtm.csv\", header = None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bow = np.matrix(x_bow_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cut = int(0.8*x_bow.shape[0])\n",
    "cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_bow_train = x_bow[:cut] \n",
    "x_bow_test = x_bow[cut:]\n",
    "x_bow_train.shape, x_bow_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 24680)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "sparse_Xtr = sparse.coo_matrix(x_bow).tocsr()\n",
    "fh.save_sparse(sparse_Xtr, os.path.join(raw_data_path, \"scholar_gamma\"+str(gamma), \"train.npz\"))\n",
    "# test\n",
    "#sparse_Xte = sparse.coo_matrix(x_bow_test).tocsr()\n",
    "#fh.save_sparse(sparse_Xte, os.path.join(raw_data_path, \"scholar\", \"test.npz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insample\n",
    "train_ids = [\"train_\" + str(x) for x in list(range(n_obs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh.write_to_json(train_ids, output_dir + \"train.ids.json\", indent=2, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.0\n"
     ]
    }
   ],
   "source": [
    "if gamma == 0.5:\n",
    "    semisynth_data = pd.read_csv(raw_data_path + \"yelp_semisynth_sample_gamma0.5.csv\",header = 0)\n",
    "    print(\"gamma: 0.5\")\n",
    "elif int(gamma) == 1:\n",
    "    semisynth_data = pd.read_csv(raw_data_path + \"yelp_semisynth_sample_gamma1.0.csv\",header = 0)\n",
    "    print(\"gamma: 1.0\")\n",
    "elif int(gamma) == 0:\n",
    "    semisynth_data = pd.read_csv(raw_data_path + \"yelp_semisynth_sample_gamma0.0.csv\",header = 0)\n",
    "    print(\"gamma: 0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 18)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semisynth_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>name_u</th>\n",
       "      <th>review_count_u</th>\n",
       "      <th>stars_av_u</th>\n",
       "      <th>name_b</th>\n",
       "      <th>stars_av_b</th>\n",
       "      <th>review_count_b</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>US</th>\n",
       "      <th>PrUS</th>\n",
       "      <th>synth_y</th>\n",
       "      <th>doc_idx</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>harvard_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__8j8yhsmE98wNWHJNyAgw</td>\n",
       "      <td>z3gSZ8lkZLZyxSHFNuzM0A</td>\n",
       "      <td>ewqmng8J2Q66QXDyWc_3lw</td>\n",
       "      <td>1</td>\n",
       "      <td>K'Lee</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Urawa Sushi</td>\n",
       "      <td>3.0</td>\n",
       "      <td>91</td>\n",
       "      <td>mindblown time order food never deliveri bad o...</td>\n",
       "      <td>-0.699038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.444489</td>\n",
       "      <td>1</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>-0.643889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__8j8yhsmE98wNWHJNyAgw</td>\n",
       "      <td>llgsKCdEdDnSU5LZnL92Jw</td>\n",
       "      <td>ngCyo4dT0YEJKlHcp3UQow</td>\n",
       "      <td>4</td>\n",
       "      <td>Dasa</td>\n",
       "      <td>59</td>\n",
       "      <td>4.10</td>\n",
       "      <td>Urawa Sushi</td>\n",
       "      <td>3.0</td>\n",
       "      <td>91</td>\n",
       "      <td>order ubereat night love menu huge tunasalmon ...</td>\n",
       "      <td>0.444332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.719348</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.898863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__8j8yhsmE98wNWHJNyAgw</td>\n",
       "      <td>gV9Y1fHKqnMRExRErIvFag</td>\n",
       "      <td>uE71Nvq6sKYtE4w_vyJngw</td>\n",
       "      <td>1</td>\n",
       "      <td>Eric</td>\n",
       "      <td>163</td>\n",
       "      <td>3.32</td>\n",
       "      <td>Urawa Sushi</td>\n",
       "      <td>3.0</td>\n",
       "      <td>91</td>\n",
       "      <td>easili worst sushi place ever order absolut id...</td>\n",
       "      <td>-0.189458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.944093</td>\n",
       "      <td>3</td>\n",
       "      <td>0.136905</td>\n",
       "      <td>-0.113219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                 user_id               review_id  \\\n",
       "0  __8j8yhsmE98wNWHJNyAgw  z3gSZ8lkZLZyxSHFNuzM0A  ewqmng8J2Q66QXDyWc_3lw   \n",
       "1  __8j8yhsmE98wNWHJNyAgw  llgsKCdEdDnSU5LZnL92Jw  ngCyo4dT0YEJKlHcp3UQow   \n",
       "2  __8j8yhsmE98wNWHJNyAgw  gV9Y1fHKqnMRExRErIvFag  uE71Nvq6sKYtE4w_vyJngw   \n",
       "\n",
       "   stars name_u  review_count_u  stars_av_u       name_b  stars_av_b  \\\n",
       "0      1  K'Lee               3        2.00  Urawa Sushi         3.0   \n",
       "1      4   Dasa              59        4.10  Urawa Sushi         3.0   \n",
       "2      1   Eric             163        3.32  Urawa Sushi         3.0   \n",
       "\n",
       "   review_count_b                                         text_clean  \\\n",
       "0              91  mindblown time order food never deliveri bad o...   \n",
       "1              91  order ubereat night love menu huge tunasalmon ...   \n",
       "2              91  easili worst sushi place ever order absolut id...   \n",
       "\n",
       "   sentiment   US  PrUS   synth_y  doc_idx  pos_score  harvard_score  \n",
       "0  -0.699038  0.0   0.5  2.444489        1   0.105263      -0.643889  \n",
       "1   0.444332  1.0   0.5  3.719348        2   0.363636       1.898863  \n",
       "2  -0.189458  0.0   0.5  2.944093        3   0.136905      -0.113219  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semisynth_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = semisynth_data.synth_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.index = train_ids\n",
    "train_y.to_csv(output_dir + \"train.target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_0        2.444489\n",
       "train_1        3.719348\n",
       "train_2        2.944093\n",
       "train_3        1.616667\n",
       "train_4        4.137294\n",
       "                 ...   \n",
       "train_49995    2.140177\n",
       "train_49996    4.371907\n",
       "train_49997    1.298292\n",
       "train_49998    1.433057\n",
       "train_49999    5.225657\n",
       "Name: synth_y, Length: 50000, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_covars = semisynth_data[[\"US\",\"stars_av_b\"]].astype(\"float32\") # choose which features to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_covars.index = train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_covars.to_csv(output_dir + \"train.covars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_covars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US</th>\n",
       "      <th>stars_av_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_49995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_49996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_49997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_49998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_49999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              US  stars_av_b\n",
       "train_0      0.0         3.0\n",
       "train_1      1.0         3.0\n",
       "train_2      0.0         3.0\n",
       "train_3      1.0         3.0\n",
       "train_4      0.0         3.0\n",
       "...          ...         ...\n",
       "train_49995  1.0         3.0\n",
       "train_49996  1.0         3.0\n",
       "train_49997  0.0         3.0\n",
       "train_49998  1.0         3.0\n",
       "train_49999  1.0         3.0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_covars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_tt = \"/nfs/home/maxa/data/semisynth_btr/scholar_split/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df = pd.read_csv(raw_data_path +'preprocessed/booking_synth_vocab.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaabsolut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abbbey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abbey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16332</th>\n",
       "      <td>zud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16333</th>\n",
       "      <td>zuid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16334</th>\n",
       "      <td>zur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16335</th>\n",
       "      <td>zurich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16336</th>\n",
       "      <td>zzstaff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16337 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x1\n",
       "0      aaabsolut\n",
       "1          aback\n",
       "2        abandon\n",
       "3         abbbey\n",
       "4          abbey\n",
       "...          ...\n",
       "16332        zud\n",
       "16333       zuid\n",
       "16334        zur\n",
       "16335     zurich\n",
       "16336    zzstaff\n",
       "\n",
       "[16337 rows x 1 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16337"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(vocab_df[\"x1\"])\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh.write_to_json(vocab, output_dir_tt + \"train.vocab.json\", indent=2, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 16337)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut = int(0.8*x_bow.shape[0])\n",
    "cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 16337), (10000, 16337))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bow_train = x_bow[:cut] \n",
    "x_bow_test = x_bow[cut:]\n",
    "x_bow_train.shape, x_bow_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "sparse_Xtr = sparse.coo_matrix(x_bow_train).tocsr()\n",
    "fh.save_sparse(sparse_Xtr, os.path.join(raw_data_path, \"scholar_split\", \"train.npz\"))\n",
    "# test\n",
    "sparse_Xte = sparse.coo_matrix(x_bow_test).tocsr()\n",
    "fh.save_sparse(sparse_Xte, os.path.join(raw_data_path, \"scholar_split\", \"test.npz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [\"train_\" + str(x) for x in list(range(x_bow_train.shape[0]))]\n",
    "test_ids = [\"test_\" + str(x) for x in list(range(x_bow_test.shape[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh.write_to_json(train_ids, output_dir_tt + \"train.ids.json\", indent=2, sort_keys=True)\n",
    "fh.write_to_json(test_ids, output_dir_tt + \"test.ids.json\", indent=2, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "semisynth_data = pd.read_csv(raw_data_path + \"booking_semisynth_sample.csv\",header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 18)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semisynth_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Leisure</th>\n",
       "      <th>Couple</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>doc_idx</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>pos_prop</th>\n",
       "      <th>av_score</th>\n",
       "      <th>synth_y</th>\n",
       "      <th>bar_rest</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.1</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>17</td>\n",
       "      <td>6373</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Everything was great Cozy clean and just perf...</td>\n",
       "      <td>everyth great cozi clean just perfect breakfas...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.062683</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>-0.501244</td>\n",
       "      <td>3.547939</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.5</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>20</td>\n",
       "      <td>2197</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Good location .  We travel through to Kensing...</td>\n",
       "      <td>good locat travel kensington everi week great ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.645357</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-1.574335</td>\n",
       "      <td>0.105846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average_Score Reviewer_Nationality  Review_Total_Negative_Word_Counts  \\\n",
       "0            8.1             Hungary                                  17   \n",
       "1            7.5      United Kingdom                                  20   \n",
       "\n",
       "   Total_Number_of_Reviews  Review_Total_Positive_Word_Counts  \\\n",
       "0                     6373                                 12   \n",
       "1                     2197                                  4   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  Leisure  \\\n",
       "0                                           6            10.0        0   \n",
       "1                                          21             5.4        0   \n",
       "\n",
       "   Couple                                               text  \\\n",
       "0       0   Everything was great Cozy clean and just perf...   \n",
       "1       1   Good location .  We travel through to Kensing...   \n",
       "\n",
       "                                          text_clean  doc_idx  sentiment  \\\n",
       "0  everyth great cozi clean just perfect breakfas...        1   1.062683   \n",
       "1  good locat travel kensington everi week great ...        2   0.645357   \n",
       "\n",
       "   pos_prop  av_score   synth_y  bar_rest  conf  \n",
       "0  0.413793 -0.501244  3.547939         0     0  \n",
       "1  0.166667 -1.574335  0.105846         0     0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semisynth_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = semisynth_data.synth_y\n",
    "train_y = data_y[:cut]\n",
    "test_y = data_y[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.index = train_ids\n",
    "train_y.to_csv(output_dir_tt + \"train.target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_0         3.547939\n",
       "train_1         0.105846\n",
       "train_2        -0.681302\n",
       "train_3         1.719629\n",
       "train_4         3.303026\n",
       "                 ...    \n",
       "train_39995     6.130856\n",
       "train_39996     1.963663\n",
       "train_39997     1.792113\n",
       "train_39998    10.060682\n",
       "train_39999     9.967898\n",
       "Name: synth_y, Length: 40000, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.index = test_ids\n",
    "test_y.to_csv(output_dir_tt + \"test.target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_0        9.388680\n",
       "test_1        9.416876\n",
       "test_2        2.281902\n",
       "test_3        3.232687\n",
       "test_4        4.279789\n",
       "               ...    \n",
       "test_9995    11.059970\n",
       "test_9996     9.632751\n",
       "test_9997     1.672547\n",
       "test_9998     2.189951\n",
       "test_9999     5.829085\n",
       "Name: synth_y, Length: 10000, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_covars = semisynth_data[[\"Leisure\",\"av_score\"]].astype(\"float32\") # choose which features to include\n",
    "train_covars = data_covars[:cut]\n",
    "test_covars = data_covars[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_covars.index = train_ids\n",
    "train_covars.to_csv(output_dir_tt + \"train.covars.csv\")\n",
    "test_covars.index = test_ids\n",
    "test_covars.to_csv(output_dir_tt + \"test.covars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 2), (10000, 2))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_covars.shape, test_covars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
